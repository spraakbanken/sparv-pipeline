"""Snakefile used by Snakemake."""
import os
from pathlib import Path

import snakemake.io
from snakemake.logging import logger

from sparv import util
from sparv.core import config as sparv_config
from sparv.core import paths, registry, snake_utils

# Remove Snakemake's default log handler
if config.get("run_by_sparv") and logger.log_handler and logger.log_handler[0] == logger.text_handler:
    logger.log_handler = []

# Don't do anything if no rule was specified
rule do_nothing:
    input: []

# ==============================================================================
# Dynamic Creation of Snakemake Rules
# ==============================================================================

def make_rules(config_missing: bool) -> None:
    """Load all Sparv modules and create Snakemake rules."""
    # Find and load Sparv modules
    registry.find_modules()

    # Create rules for all available annotation functions
    for module_name in registry.annotators:
        for f_name in registry.annotators[module_name]:
            annotator = registry.annotators[module_name][f_name]
            make_rule(module_name, f_name, annotator, config_missing)

    # Check and set rule orders
    ordered_rules = snake_utils.check_ruleorder(snake_storage)
    for rule1, rule2 in ordered_rules:
        workflow.ruleorder(rule1.rule_name, rule2.rule_name)
        # ruleorder:  rule1.rule_name > rule2.rule_name


def make_rule(module_name: str, f_name: str, annotator_info: dict, config_missing: bool = False) -> None:
    """Create single Snakemake rule."""
    # Init rule storage
    rule_storage = snake_utils.RuleStorage(module_name, f_name, annotator_info)

    # Process rule parameters and update rule storage
    snake_utils.rule_helper(rule_storage, config, snake_storage, config_missing)

    if rule_storage:
        # Create a named Snakemake rule for annotator (unfortunately we cannot use the regular snakemake syntax for this)
        @workflow.rule(name=rule_storage.rule_name)
        @workflow.message(rule_storage.target_name)
        @workflow.input(rule_storage.inputs)
        @workflow.output(rule_storage.outputs)
        @workflow.params(module_name=rule_storage.module_name,
                         f_name=rule_storage.f_name,
                         parameters=snake_utils.get_parameters(rule_storage),
                         pid=os.getpid(),
                         log=config.get("log"))
        # We use "script" instead of "run" since with "run" the whole Snakefile would have to be reloaded for every
        # single job, due to how Snakemake creates processes for run-jobs.
        @workflow.script("run_snake.py")
        @workflow.run
        def __rule__(input_, output, params, wildcards, threads, resources, log, version, rule, conda_env, container_img,
                     singularity_args, use_singularity, env_modules, bench_record, jobid, is_shell, bench_iteration,
                     cleanup_scripts, shadow_dir):
            script("run_snake.py", paths.sparv_path / "core", input_, output, params,
                   wildcards, threads, resources, log, config, rule, conda_env, container_img, singularity_args,
                   env_modules, bench_record, jobid, bench_iteration, cleanup_scripts, shadow_dir)

        # Create rule to run this annotation on all input files
        make_all_files_rule(rule_storage)


def make_all_files_rule(rule_storage: snake_utils.RuleStorage) -> None:
    """Create named rule to run an annotation on all input files."""
    # Only create rule when explicitly called
    if config.get("run_by_sparv") and rule_storage.target_name not in config.get("targets", []):
        return

    # Get user-supplied wildcard values
    wildcards = dict(wc.split("=") for wc in config.get("wildcards", []))

    # Get Snakemake rule object
    sm_rule = getattr(rules, rule_storage.rule_name).rule

    # Prepend annotation dir to paths if needed (usually included in the {doc} wildcard but here it needs to be explicit)
    rule_outputs = [paths.annotation_dir / o if not (paths.annotation_dir in o.parents or paths.export_dir in o.parents)
                    else o
                    for o in rule_storage.outputs]

    # Expand {doc} wildcard to every corpus document
    rule_outputs = expand(rule_outputs,
                          doc=config.get("doc") or snake_utils.get_source_files(snake_storage.source_files),
                          **wildcards)

    # Convert paths to IOFile objects so Snakemake knows which rule they come from (in case of ambiguity)
    rule_outputs = [snakemake.io.IOFile(f, rule=sm_rule) for f in rule_outputs]

    @workflow.rule(name=rule_storage.target_name)
    @workflow.input(rule_outputs)
    @workflow.norun()
    @workflow.run
    def __rule__(*_args, **_kwargs):
        pass


# Init the storage for some essential variables involving all rules
snake_storage = snake_utils.SnakeStorage()

# Find and load corpus config
config_missing = snake_utils.load_config(config)

# Load modules and create automatic rules
make_rules(config_missing)


# ==============================================================================
# Static Snakemake Rules
# ==============================================================================

# Rule to list all config options and their current values
rule config:
    run:
        if config.get("options"):
            out_conf = {}
            for k in config["options"]:
                out_conf[k] = sparv_config.get(k)
        else:
            out_conf = sparv_config.config
        print(snake_utils.prettify_config(out_conf))


# Rule to list all annotations
rule annotations:
    run:
        all_annotations = snake_storage.all_annotations
        max_len = max(len(a[0]) for m in all_annotations for f in all_annotations[m]
                      for a in all_annotations[m][f]["annotations"]) + 4
        print()
        print("Available modules, annotators and annotations")
        print("=============================================\n")
        for module_name in sorted(all_annotations):
            print(util.Color.BOLD + "{}".format(module_name.upper()) + util.Color.RESET)
            for f_name in sorted(all_annotations[module_name]):
                print("      {}{}{}".format(util.Color.UNDERLINE, f_name, util.Color.RESET))
                f_desc = all_annotations[module_name][f_name]["description"]
                if f_desc:
                    print("      {}".format(f_desc))
                print()
                f_anns = all_annotations[module_name][f_name]["annotations"]
                for f_ann in sorted(f_anns):
                    print("        â€¢ {:{width}}{}".format(f_ann[0], f_ann[1] or "", width=max_len))
                    if f_ann[0].cls:
                        print(util.Color.ITALIC + "          <{}>".format(f_ann[0].cls) + util.Color.RESET)
                print()
            print("\n")

        max_len = max(len(cls) for cls in registry.annotation_classes["module_classes"]) + 8

        print("Available classes")
        print("=================\n")
        print(util.Color.BOLD + "    Classes defined by pipeline modules" + util.Color.RESET)
        print("        {}{:{}}    {}{}".format(util.Color.ITALIC, "Class", max_len, "Annotation", util.Color.RESET))
        for cls, anns in registry.annotation_classes["module_classes"].items():
            print("        {:{}}    {}".format(cls, max_len, anns[0]))
            if len(anns) > 1:
                for ann in anns[1:]:
                    print("        {:{}}    {}".format("", max_len, ann))

        if registry.annotation_classes["config_classes"]:
            print()
            print(util.Color.BOLD + "    Classes from config" + util.Color.RESET)
            print("        {}{:{}}    {}{}".format(util.Color.ITALIC, "Class", max_len, "Annotation", util.Color.RESET))
            for cls, ann in registry.annotation_classes["config_classes"].items():
                print("        {:{}}    {}".format(cls, max_len, ann))
        print()


# Rule to list all annotation presets
rule presets:
    run:
        resolved_presets = dict(
            (i, sparv_config.resolve_presets(sparv_config.presets[i])) for i in sparv_config.presets)
        print(snake_utils.prettify_config(resolved_presets))


# Rule to list all targets
rule list_targets:
    run:
        max_len = max(len(t[0]) for t in snake_storage.named_targets + snake_storage.export_targets
                      + snake_storage.install_targets + snake_storage.model_targets) + 4
        print()
        print("Available targets")
        print("=================\n")
        print("    EXPORTS")
        for target, desc, _lang in sorted(snake_storage.export_targets):
            print("        {:{}}    {}".format(target, max_len, desc))
        print()
        print("    INSTALLERS")
        for target, desc in sorted(snake_storage.install_targets):
            print("        {:{}}    {}".format(target, max_len, desc))
        print()
        print("    ANNOTATIONS")
        for target, desc in sorted(snake_storage.named_targets):
            print("        {:{}}    {}".format(target, max_len, desc))
        print()
        print("    MODEL BUILDERS")
        for target, desc, _lang in sorted(snake_storage.model_targets):
            print("        {:{}}    {}".format(target, max_len, desc))


# Rule to list all exports
rule list_exports:
    run:
        max_len = max(len(t[0]) for t in snake_storage.export_targets) + 4
        print()
        print("Available corpus output formats (exports)")
        print("=========================================")
        for target, desc, language in sorted(snake_storage.export_targets):
            if not language or sparv_config.get("metadata.language") in language:
                print("    {:{}}    {}".format(target, max_len, desc))
        print()
        print("Default: xml_export:pretty")
        print()


# Rule to list all input files
rule files:
    run:
        print("Available input files:\n")
        print(", ".join(snake_utils.get_source_files(snake_storage.source_files)))


# Rule to remove annotations dir
rule clean:
    run:
        # Only run if corpus config is found in same dir
        if config_missing:
            print("No corpus config found. Not removing anything.")
        else:
            import shutil
            to_remove = []
            if config.get("export") or config.get("all"):
                to_remove.append(paths.export_dir)
                assert paths.export_dir, "Export dir name not configured."
            if config.get("all") or not config.get("export"):
                to_remove.append(paths.annotation_dir)
                assert paths.annotation_dir, "Annotations dir name not configured."

            something_removed = False
            for d in to_remove:
                full_path = Path.cwd() / d
                if full_path.is_dir():
                    shutil.rmtree(full_path)
                    print(d, "directory removed")
                    something_removed = True
            if not something_removed:
                print("Nothing to remove")


# Rule to list all installations that will be made when running `sparv install`
rule list_installs:
    run:
        max_len = max(len(t[0]) for t in snake_storage.install_targets) + 4
        print()
        print("Installations to be made")
        print("========================")
        for target, desc in sorted(snake_storage.install_targets):
            if target in sparv_config.get("korp.install", []):
                print("    {:{}}    {}".format(target, max_len, desc))
        print()
        print("Other available installations")
        print("=============================")
        for target, desc in sorted(snake_storage.install_targets):
            if target not in sparv_config.get("korp.install", []):
                print("    {:{}}    {}".format(target, max_len, desc))
        print()


# Rule for making installations
rule install_annotated_corpus:
    input:
        snake_utils.get_install_targets(snake_storage.install_outputs)


# Rule to list all models that can be built/downloaded
rule list_models:
    run:
        max_len = max(len(t[0]) for t in snake_storage.model_targets) + 4
        print()
        print("Models for current language ({})".format(sparv_config.get("metadata.language")))
        print("=================================")
        for target, desc, language in sorted(snake_storage.model_targets):
            if language and sparv_config.get("metadata.language") in language:
                print("    {:{}}    {}".format(target, max_len, desc))
        print()
        print("Language-independent models")
        print("===========================")
        for target, desc, language in sorted(snake_storage.model_targets):
            if not language:
                print("    {:{}}    {}".format(target, max_len, desc))
        print()


# Build all models. Build even the non-optional ones if force_optional_models = True.
rule build_models:
    input:
        snake_storage.model_outputs
